# DataCamp_DataScience
Data Camp Data Science Exercises 

## [Introduction to Statistics](https://github.com/toyinolape/DataCamp_DataScience/tree/master/Statistics)
Statistics is the study of how to collect, analyze, and draw conclusions from data. It’s a hugely valuable tool that you can use to bring the future into focus and infer the answer to tons of questions. For example, what is the likelihood of someone purchasing your product, how many calls will your support team receive, and how many jeans sizes should you manufacture to fit 95% of the population? In this folder ther is a notebook that shows how, most situations are covered, using scatterplots to show the relationship between numeric values, and calculating correlation. Probability was also tackled, the backbone of statistical reasoning, and how to use Python to conduct a well-designed study to draw your own conclusions from data.

## [Pandas_Library](https://github.com/toyinolape/DataCamp_DataScience/tree/master/Pandas_Library)
pandas DataFrames are the most widely used in-memory representation of complex data collections within Python. Whether in finance, a scientific field, or data science, familiarity with pandas is essential. This repo shows you how to work with real-world datasets containing both string and numeric data, often structured around time series. I will also show how to perfomr powerful analysis, selection, and visualization techniques.


## [Supervised Learning with Scikit-Learn](https://github.com/toyinolape/DataCamp_DataScience/tree/master/Supervised_Learning)
Machine learning is the field that teaches machines and computers to learn from existing data to make predictions on new data: Will a tumor be benign or malignant? Which of your customers will take their business elsewhere? Is a particular email spam? In this folder ther are two notebooks [Classfication](https://github.com/toyinolape/DataCamp_DataScience/blob/master/Supervised_Learning/Classification.ipynb) and [Linear Regression](https://github.com/toyinolape/DataCamp_DataScience/blob/master/Supervised_Learning/Linear_Regression.ipynb).  These notebooks show you how to build predictive models, tune their parameters, and determine how well they will perform with unseen data—all while using real world datasets. I'll be using scikit-learn, one of the most popular and user-friendly machine learning libraries for Python.

## [Feature Engineering for Machine Learning in Python](https://github.com/toyinolape/DataCamp_DataScience/tree/master/Feature_Engineering)
Feature engineering is the process of using data’s domain knowledge to create features that make machine learning algorithms work. It’s the act of extracting important features from raw data and transforming them into formats that are suitable for machine learning. To perform feature engineering, a data scientist combines domain knowledge (knowledge about a specific field) with math and programming skills to transform or come up with new features that will help a machine learning model perform better. Feature engineering is a practical area of machine learning and is one of the most important aspects of it.

## [Intoduction to SQL](https://github.com/toyinolape/DataCamp_DataScience/tree/master/Intro_SQL)
SQL, which stands for Structured Query Language, is a language for interacting with data stored in something called a relational database.A relational database as a collection of tables. A table is just a set of rows and columns, like a spreadsheet, which represents exactly one type of entity. For example, a table might represent employees in a company or purchases made, but not both.
Each row, or record, of a table contains information about a single entity. For example, in a table representing employees, each row represents a single person. Each column, or field, of a table contains a single attribute for all rows in the table. For example, in a table representing employees, we might have a column containing first and last names for all employees.

## [Deep Learning]()
Deep learning is here to stay! It's the go-to technique to solve complex problems that arise with unstructured data and an incredible tool for innovation. Keras is one of the frameworks that make it easier to start developing deep learning models, and it's versatile enough to build industry-ready models in no time. In this course, you will learn regression and save the earth by predicting asteroid trajectories, apply binary classification to distinguish between real and fake dollar bills, use multiclass classification to decide who threw which dart at a dart board, learn to use neural networks to reconstruct noisy images and much more. Additionally, you will learn how to better control your models during training and how to tune them to boost their performance.